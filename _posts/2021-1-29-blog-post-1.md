---
title: 'Deep Neural Networks on FPGA exploiting Partial Reconfiguration'
date: 2021-1-29
permalink: /posts/2021/1/blog-post-1/

tags:
  - AI 반도체
  - FPGA
  - Neural Networks
  - Partial Reconfiguration
---

Last month, I found that there's some 'AI hardware design contest'([AI 반도체 경연대회](https://view.asiae.co.kr/article/2020111611412444851)) going on. The contestants are given the neural network(NN) SW source code and what they need to do is implement it well on the FPGA. The final design will be evaluated based on its throughput, resource usage, design novelty, and whatever criterion the contestants think their designs excel on. It would have made more sense if the contestants come up with their own algorithms as HW and SW are tightly coupled, but the organizer must be afraid that the competition may end up in algorithm contest. 

I thought, if I exploit Partial Reconfiguration in this context, I could probably win in novelty because I utilize FPGA’s special characteristic when FPGA is given to prototype ASIC. I am also ready to argue this approach is complementary with other efficient implementations of each layer! I wasn’t 100% buying the idea of exploiting PR in this context, so I ended up not participating in the design contest, but I share what I found about previous work done in this topic.

What is Partial Reconfiguration(PR)?
======
Partial Reconfiguration(PR) is a feature of a modern FPGAs that the part of the design is dynamically modified on runtime while the remaining of the design is still running. As can be seen in the figure below, the part of the design, which was initially configured with A1.bit, can be reconfigured with A2.bit, A3.bit or A4.bit while the “static” logic is unaffected. These bitstreams, A1.bit, A2.bit, A3.bit, and A4.bit are called partial bitstreams.
<p align="center"> <img src="https://dj-park.github.io/images/posts_img/pr.png"> </p>
<p style="font-family: times, serif; font-size:10pt; font-style:italic; text-align:center; color:grey; margin-top:1px">
    Partial Reconfiguration, Example
</p>
PR leads to an area reduction to the system that has mutually exclusive functionality. For instance, the design below originally has multiplexers with three functions to choose. In this ASIC style design, only one of the three functions is active at a time.
<p align="center"> <img src="https://dj-park.github.io/images/posts_img/xilinx1.JPG"> </p>
<p style="font-family: times, serif; font-size:10pt; font-style:italic; text-align:center; color:grey">
    Network Switch WITHOUT Partial Reconfiguration [1]
</p>
On the other hand, PR removes this inefficiency by dynamically reconfiguring functions when needed. Plus, when the function associated with Port 1 is reconfigured, others ports can run unaffected.
<p align="center"> <img src="https://dj-park.github.io/images/posts_img/xilinx2.JPG"> </p>
<p style="font-family: times, serif; font-size:10pt; font-style:italic; text-align:center; color:grey">
    Network Switch WITH Partial Reconfiguration [1]
</p>
One may wonder, “If I don’t need Port2, Port3, and Port4 running when Port1 is reconfigured (like a lock-step. All ports are reconfigured together), do I need PR at all?” Yes. You can reconfigure the entire chip by loading the full bitstream instead of loading partial bitstreams. But because the bitstream loading time is proportional to the size of the bitstream, the loading time of the partial bitstream is lower than that of the full bitstream, which gives us an additional advantage. 

Related work
======
In the figure below, N similar-sized layers are time-multiplexed, resulting in 1/N resource usage or resulting in N times more parallelism. If partial bitstream loading time is negligible, the former approach maintains latency and throughput suffers to 1/N. The latter approach could result in some benefit in latency and potentially in throughput as well, but its bitstream loading times might not be negligible.
<p align="center"> <img src="https://dj-park.github.io/images/posts_img/PR_NN_layers.png"> </p>
<p style="font-family: times, serif; font-size:10pt; font-style:italic; text-align:center; color:grey">
    (1) is a design without PR. (2) has the same size of layers with (1), but because it time-multiplexes each layer, it costs 1/3 resources. (2) may have similar latency for a single data with (1), but throughput suffers. (3) has the 3-times size of layers of (1), which leads to more parallelism. However, bitstream loading time must be an overhead.  
</p>

Among some of the related works I found, [2] is a survey paper on PR(very comprehensive and educational!), and it suggests a dynamically evolving neural networks can utilize PR. 

[3] introduces scenarios where PR achieves better throughput per a given area or better latency per a given area. I really like the work, especially when the authors interleave two PR regions to hide partial bitstream configuration time.


**WORK IN PROGRESS**


References
------
1. UG909: Vivado Design Suite User Guide: Partial Reconfiguration, Xilinx, Inc., 2100 Logic Drive, San Jose, CA 95124, April 2018. [Online]. Available: https://www.xilinx.com/support/documentation/sw_manuals/xilinx2018_1/ug909-vivado-partial-reconfiguration.pdf
2. K. Vipin and S. A. Fahmy, "FPGA dynamic and partial reconfiguration: A survey of architectures methods and applications", ACM Computing Surveys, Sep. 2018.
3. M. Nguyen, N. Serafin, and J. C. Hoe, "Partial Reconfiguration for Design Optimization
